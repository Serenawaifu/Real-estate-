# robots.txt for DGrealtors
# This file is used to manage the behavior of web crawlers and bots

User -agent: *
Allow: /
Disallow: /api/
Disallow: /admin/
Disallow: /private/
Disallow: *.pdf$

# Sitemap locations
Sitemap: https://dgrealtors.in/sitemap.xml
Sitemap: https://dgrealtors.in/sitemap-images.xml

# Crawl-delay for responsible crawling
Crawl-delay: 1

# Specific bot rules
User -agent: Googlebot
Allow: /
Crawl-delay: 0

User -agent: Bingbot
Allow: /
Crawl-delay: 1

# Block known bad bots
User -agent: AhrefsBot
Disallow: /

User -agent: SemrushBot
Disallow: /

User -agent: DotBot
Disallow: /

User -agent: MJ12bot
Disallow: /

# Allow social media bots
User -agent: facebookexternalhit
Allow: /

User -agent: Twitterbot
Allow: /

User -agent: LinkedInBot
Allow: /

User -agent: WhatsApp
Allow: /

User -agent: Slackbot
Allow: /
